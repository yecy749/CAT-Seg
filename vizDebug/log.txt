[06/03 21:43:42] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 21:43:42] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 21:43:42] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 21:43:42] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 21:43:42] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 21:43:42] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 21:43:42] d2.utils.env INFO: Using a generated random seed 42880425
[06/03 21:43:46] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 21:43:46] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 21:43:46] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 21:45:54] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 21:45:55] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 21:45:55] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 21:45:55] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 21:45:55] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 21:45:55] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 21:45:55] d2.utils.env INFO: Using a generated random seed 55169879
[06/03 21:45:58] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 21:45:58] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 21:45:58] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 21:45:58] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 21:45:58] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 21:45:58] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 21:45:58] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 21:45:58] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 21:45:58] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 21:45:58] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 21:47:09] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 21:47:09] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 21:47:09] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 21:47:09] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 21:47:09] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 21:47:09] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 21:47:09] d2.utils.env INFO: Using a generated random seed 9674513
[06/03 21:47:12] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 21:47:12] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 21:47:12] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 21:47:13] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 21:47:13] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 21:47:13] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 21:47:13] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 21:47:13] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 21:47:13] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 21:47:13] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 21:47:50] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 21:47:51] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 21:47:51] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 21:47:51] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 21:47:51] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 21:47:51] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 21:47:51] d2.utils.env INFO: Using a generated random seed 51243343
[06/03 21:47:54] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 21:47:54] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 21:47:54] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 21:47:54] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 21:47:54] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 21:47:54] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 21:47:54] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 21:47:54] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 21:47:54] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 21:47:54] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 21:48:04] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 21:48:05] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 21:48:05] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 21:48:05] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 21:48:05] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 21:48:05] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 21:48:05] d2.utils.env INFO: Using a generated random seed 5227633
[06/03 21:48:08] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 21:48:08] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 21:48:08] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 21:48:08] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 21:48:08] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 21:48:08] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 21:48:08] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 21:48:08] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 21:48:08] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 21:48:08] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 21:58:03] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 21:58:03] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 21:58:03] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 21:58:03] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 21:58:03] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 21:58:03] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 21:58:03] d2.utils.env INFO: Using a generated random seed 3514040
[06/03 21:58:37] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 21:58:37] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 21:58:37] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 21:58:37] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 21:58:37] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 21:58:37] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 21:58:37] d2.utils.env INFO: Using a generated random seed 37743133
[06/03 21:58:40] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 21:58:40] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 21:58:40] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 21:58:41] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 21:58:41] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 21:58:41] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 21:58:41] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 21:58:41] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 21:58:41] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 21:58:41] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:00:43] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:00:43] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:00:43] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:00:43] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:00:43] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:00:43] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:00:43] d2.utils.env INFO: Using a generated random seed 43662580
[06/03 22:00:47] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:00:47] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:00:47] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:00:47] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:00:47] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:00:47] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:00:47] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:00:47] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:00:47] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:00:47] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:04:07] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:04:07] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:04:07] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:04:07] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:04:07] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:04:07] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:04:07] d2.utils.env INFO: Using a generated random seed 7595862
[06/03 22:04:10] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:04:10] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:04:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:04:11] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:04:11] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:04:11] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:04:11] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:04:11] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:04:11] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:04:11] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:06:17] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:06:17] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:06:17] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:06:17] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:06:17] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:06:17] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:06:17] d2.utils.env INFO: Using a generated random seed 18041967
[06/03 22:06:49] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:06:49] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:06:49] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:06:49] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:06:49] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:06:49] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:06:49] d2.utils.env INFO: Using a generated random seed 49805887
[06/03 22:09:23] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:09:23] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:09:23] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:09:23] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:09:23] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:09:23] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:09:23] d2.utils.env INFO: Using a generated random seed 23759282
[06/03 22:13:20] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:13:21] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:13:21] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:13:21] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:13:21] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:13:21] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:13:21] d2.utils.env INFO: Using a generated random seed 21128663
[06/03 22:14:06] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:14:06] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:14:06] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:14:06] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:14:06] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:14:06] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:14:06] d2.utils.env INFO: Using a generated random seed 6988374
[06/03 22:14:10] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:14:10] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:14:10] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:14:10] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:14:10] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:14:10] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:14:10] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:14:10] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:14:10] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:14:10] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:15:15] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:15:16] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:15:16] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:15:16] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:15:16] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:15:16] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:15:16] d2.utils.env INFO: Using a generated random seed 16124512
[06/03 22:15:19] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:15:19] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:15:19] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:15:19] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:15:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:15:19] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:15:19] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:15:19] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:15:19] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:15:19] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:18:08] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:18:08] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:18:08] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:18:08] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:18:08] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:18:08] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:18:08] d2.utils.env INFO: Using a generated random seed 8937468
[06/03 22:18:11] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:18:11] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:18:11] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:18:12] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:18:12] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:18:12] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:18:12] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:18:12] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:18:12] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:18:12] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:21:31] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:21:32] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:21:32] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:21:32] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:21:32] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:21:32] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:21:32] d2.utils.env INFO: Using a generated random seed 32332013
[06/03 22:21:35] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:21:35] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:21:35] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:21:35] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:21:35] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:21:35] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:21:35] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:21:35] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:21:35] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:21:35] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:25:22] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:25:22] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:25:22] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:25:22] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:25:22] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:25:23] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:25:23] d2.utils.env INFO: Using a generated random seed 23139659
[06/03 22:25:26] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:25:26] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:25:26] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:25:26] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:25:26] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:25:26] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:25:26] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:25:26] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:25:26] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:25:26] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:41:48] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:41:48] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:41:48] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:41:48] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:41:48] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:41:48] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:41:48] d2.utils.env INFO: Using a generated random seed 48593869
[06/03 22:41:51] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:41:51] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:41:51] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:41:52] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:41:52] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:41:52] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:41:52] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:41:52] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:41:52] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:41:52] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:42:13] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:42:14] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:42:14] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:42:14] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:42:14] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:42:14] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:42:14] d2.utils.env INFO: Using a generated random seed 14463883
[06/03 22:42:17] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:42:17] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:42:17] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:42:18] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:42:18] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:42:18] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:42:18] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:42:18] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:42:18] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:42:18] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:43:14] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:43:15] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:43:15] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:43:15] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:43:15] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:43:15] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:43:15] d2.utils.env INFO: Using a generated random seed 15301038
[06/03 22:43:18] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:43:18] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:43:18] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:43:18] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:43:18] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:43:18] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:43:18] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:43:18] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:43:18] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:43:18] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:43:39] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:43:39] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:43:39] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:43:39] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:43:39] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:43:39] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:43:39] d2.utils.env INFO: Using a generated random seed 39691825
[06/03 22:43:42] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:43:42] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:43:42] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:43:43] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:43:43] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:43:43] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:43:43] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:43:43] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:43:43] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:43:43] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:44:26] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:44:26] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:44:26] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:44:26] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:44:26] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:44:26] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:44:26] d2.utils.env INFO: Using a generated random seed 27016685
[06/03 22:44:30] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:44:30] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:44:30] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:44:30] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:44:30] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:44:30] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:44:30] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:44:30] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:44:30] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:44:30] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:44:46] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:44:47] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:44:47] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:44:47] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:44:47] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:44:47] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:44:47] d2.utils.env INFO: Using a generated random seed 47206278
[06/03 22:44:50] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:44:50] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:44:50] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:44:50] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:44:50] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:44:50] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:44:50] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:44:50] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:44:50] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:44:50] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:45:43] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:45:44] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:45:44] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:45:44] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:45:44] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:45:44] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:45:44] d2.utils.env INFO: Using a generated random seed 44460227
[06/03 22:47:30] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:47:31] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:47:31] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:47:31] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:47:31] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:47:31] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:47:31] d2.utils.env INFO: Using a generated random seed 31465361
[06/03 22:47:34] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:47:34] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:47:34] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:47:34] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:47:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:47:34] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:47:34] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:47:34] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:47:34] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:47:34] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:48:00] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:48:01] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:48:01] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:48:01] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:48:01] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:48:01] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:48:01] d2.utils.env INFO: Using a generated random seed 1549750
[06/03 22:48:04] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:48:04] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:48:04] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:48:04] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:48:04] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:48:04] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:48:04] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:48:04] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:48:05] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:48:05] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:48:40] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:48:40] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:48:40] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:48:40] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:48:40] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:48:40] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:48:40] d2.utils.env INFO: Using a generated random seed 40775503
[06/03 22:48:45] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:48:45] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:48:45] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:48:45] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:48:45] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:48:46] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:48:46] d2.utils.env INFO: Using a generated random seed 46055494
[06/03 22:48:49] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:48:49] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:48:49] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:48:49] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:48:49] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:48:49] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:48:49] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:48:49] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:48:49] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:48:49] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:49:47] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:49:47] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:49:47] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:49:47] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:49:47] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:49:47] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:49:47] d2.utils.env INFO: Using a generated random seed 48032138
[06/03 22:49:51] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:49:51] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:49:51] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:49:51] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:49:51] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:49:51] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:49:51] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:49:51] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:49:51] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:49:51] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:50:30] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:50:31] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:50:31] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:50:31] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:50:31] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:50:31] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:50:31] d2.utils.env INFO: Using a generated random seed 31229227
[06/03 22:50:34] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:50:34] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:50:34] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:50:34] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:50:34] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:50:34] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:50:34] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:50:34] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:50:34] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:50:34] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:51:20] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:51:20] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:51:20] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/potsdam.json', 'DATASETS.TEST', '("potsdam_all",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:51:20] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:51:20] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - potsdam_all
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/potsdam.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:51:20] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:51:20] d2.utils.env INFO: Using a generated random seed 21061137
[06/03 22:51:23] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:51:23] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:51:23] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:51:24] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:51:24] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:51:24] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:51:24] d2.data.common INFO: Serializing 1368 elements to byte tensors and concatenating them all ...
[06/03 22:51:24] d2.data.common INFO: Serialized dataset takes 0.25 MiB
[06/03 22:51:24] d2.data.datasets.coco INFO: Loaded 1368 images with semantic segmentation from /home/zpp2/ycy/datasets/PotsdamSplit/image
[06/03 22:51:24] d2.evaluation.evaluator INFO: Start inference on 1368 batches
[06/03 22:53:15] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:53:16] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:53:16] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/flair.json', 'DATASETS.TEST', '("FLAIR_test",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:53:16] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:53:16] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - FLAIR_test
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/flair.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:53:16] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:53:16] d2.utils.env INFO: Using a generated random seed 16377514
[06/03 22:53:19] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:53:19] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:53:19] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:53:19] d2.data.datasets.coco INFO: Loaded 15700 images with semantic segmentation from /home/zpp2/ycy/datasets/FLAIR/FLAIR_test/image
[06/03 22:53:19] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:53:19] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:53:19] d2.data.common INFO: Serializing 15700 elements to byte tensors and concatenating them all ...
[06/03 22:53:19] d2.data.common INFO: Serialized dataset takes 2.50 MiB
[06/03 22:53:20] d2.data.datasets.coco INFO: Loaded 15700 images with semantic segmentation from /home/zpp2/ycy/datasets/FLAIR/FLAIR_test/image
[06/03 22:53:20] d2.evaluation.evaluator INFO: Start inference on 15700 batches
[06/03 22:53:55] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:53:55] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:53:55] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/flair.json', 'DATASETS.TEST', '("FLAIR_test",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth'], resume=False)
[06/03 22:53:55] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:53:55] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - FLAIR_test
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/flair.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:53:55] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:53:55] d2.utils.env INFO: Using a generated random seed 55735236
[06/03 22:53:58] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:53:58] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:53:58] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/results/ft/model_final.pth ...
[06/03 22:53:59] d2.data.datasets.coco INFO: Loaded 15700 images with semantic segmentation from /home/zpp2/ycy/datasets/FLAIR/FLAIR_test/image
[06/03 22:53:59] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:53:59] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:53:59] d2.data.common INFO: Serializing 15700 elements to byte tensors and concatenating them all ...
[06/03 22:53:59] d2.data.common INFO: Serialized dataset takes 2.50 MiB
[06/03 22:53:59] d2.data.datasets.coco INFO: Loaded 15700 images with semantic segmentation from /home/zpp2/ycy/datasets/FLAIR/FLAIR_test/image
[06/03 22:53:59] d2.evaluation.evaluator INFO: Start inference on 15700 batches
[06/03 22:56:36] detectron2 INFO: Rank of current process: 0. World size: 1
[06/03 22:56:36] detectron2 INFO: Environment info:
-------------------------------  --------------------------------------------------------------------------------
sys.platform                     linux
Python                           3.8.19 (default, Mar 20 2024, 19:58:24) [GCC 11.2.0]
numpy                            1.22.4
detectron2                       0.6 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/detectron2
Compiler                         GCC 9.4
CUDA compiler                    CUDA 11.8
detectron2 arch flags            8.6
DETECTRON2_ENV_MODULE            <not set>
PyTorch                          2.3.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torch
PyTorch debug build              False
torch._C._GLIBCXX_USE_CXX11_ABI  False
GPU available                    Yes
GPU 0,1                          NVIDIA GeForce RTX 3090 (arch=8.6)
Driver version                   525.105.17
CUDA_HOME                        /usr/local/cuda-11.8
Pillow                           8.2.0
torchvision                      0.18.0 @/home/zpp2/anaconda3/envs/catseg/lib/python3.8/site-packages/torchvision
torchvision arch flags           3.5, 5.0, 6.0, 7.0, 7.5, 8.0, 8.6
fvcore                           0.1.5.post20221221
iopath                           0.1.9
cv2                              4.5.1
-------------------------------  --------------------------------------------------------------------------------
PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2023.1-Product Build 20230303 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.3.6 (Git Hash 86e6af5974177e513fd3fee58425e1063e7f1361)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90;-gencode;arch=compute_37,code=compute_37
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wsuggest-override -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_VERSION=2.3.0, USE_CUDA=ON, USE_CUDNN=ON, USE_CUSPARSELT=1, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_GLOO=ON, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, USE_ROCM_KERNEL_ASSERT=OFF, 

[06/03 22:56:36] detectron2 INFO: Command line arguments: Namespace(config_file='configs/vitb_384.yaml', dist_url='auto', eval_only=True, machine_rank=0, num_gpus=1, num_machines=1, opts=['OUTPUT_DIR', './vizDebug/', 'MODEL.SEM_SEG_HEAD.TEST_CLASS_JSON', 'datasets/flair.json', 'DATASETS.TEST', '("FLAIR_test",)', 'TEST.SLIDING_WINDOW', 'True', 'MODEL.SEM_SEG_HEAD.POOLING_SIZES', '[1,1]', 'SOLVER.IMS_PER_BATCH', '1', 'MODEL.WEIGHTS', '/media/zpp2/PHDD/output/new-cat-seg-results/model_base.pth'], resume=False)
[06/03 22:56:36] detectron2 INFO: Contents of args.config_file=configs/vitb_384.yaml:
_BASE_: config.yaml
MODEL:
  META_ARCHITECTURE: "CATSeg"
  PIXEL_MEAN: [123.675, 116.280, 103.530]
  PIXEL_STD: [58.395, 57.120, 57.375]
  SEM_SEG_HEAD:
    NAME: "CATSegHead"
    IN_FEATURES: ["res2", "res3", "res4"]
    IGNORE_VALUE: 255
    NUM_CLASSES: 171
    TRAIN_CLASS_JSON: "datasets/coco.json"
    TEST_CLASS_JSON: "datasets/coco.json"
    CLIP_PRETRAINED: "ViT-B/16"
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    DECODER_DIMS: [64, 32]
    DECODER_GUIDANCE_DIMS: [256, 128]
    DECODER_GUIDANCE_PROJ_DIMS: [32, 16]
    NUM_LAYERS: 2
    NUM_HEADS: 4
    HIDDEN_DIMS: 128
    POOLING_SIZES: [2, 2]
    FEATURE_RESOLUTION: [24, 24]
    WINDOW_SIZES: 12
    ATTENTION_TYPE: "linear"
    CLIP_FINETUNE: "attention"
  PROMPT_ENSEMBLE_TYPE: "single"
INPUT:
  MIN_SIZE_TRAIN: (384, )
  MIN_SIZE_TRAIN_SAMPLING: "choice"
  MIN_SIZE_TEST: 640
  CROP:
    ENABLED: True
    TYPE: "absolute"
    SIZE: (384, 384)
  SIZE_DIVISIBILITY: 384 
  FORMAT: "RGB"
  DATASET_MAPPER_NAME: "mask_former_semantic"
SOLVER:
  IMS_PER_BATCH: 4 
  LR_SCHEDULER_NAME: WarmupCosineLR
  BASE_LR: 0.0002
  MAX_ITER: 80000
  BACKBONE_MULTIPLIER: 0.0
  CLIP_MULTIPLIER: 0.01
TEST:
  EVAL_PERIOD: 5000
  
[06/03 22:56:36] detectron2 INFO: Running with full config:
CUDNN_BENCHMARK: true
DATALOADER:
  ASPECT_RATIO_GROUPING: true
  FILTER_EMPTY_ANNOTATIONS: true
  NUM_WORKERS: 8
  REPEAT_SQRT: true
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: []
  PROPOSAL_FILES_TRAIN: []
  TEST:
  - FLAIR_test
  TRAIN:
  - coco_2017_train_stuff_all_sem_seg
  VAL_ALL:
  - coco_2017_val_all_stuff_sem_seg
GLOBAL:
  HACK: 1.0
INPUT:
  COLOR_AUG_SSD: true
  CROP:
    ENABLED: true
    SINGLE_CATEGORY_MAX_AREA: 1.0
    SIZE:
    - 384
    - 384
    TYPE: absolute
  DATASET_MAPPER_NAME: mask_former_semantic
  FORMAT: RGB
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 2560
  MAX_SIZE_TRAIN: 1333
  MIN_SIZE_TEST: 640
  MIN_SIZE_TRAIN:
  - 384
  MIN_SIZE_TRAIN_SAMPLING: choice
  RANDOM_FLIP: horizontal
  SIZE_DIVISIBILITY: 384
MODEL:
  ANCHOR_GENERATOR:
    ANGLES:
    - - -90
      - 0
      - 90
    ASPECT_RATIOS:
    - - 0.5
      - 1.0
      - 2.0
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES:
    - - 32
      - 64
      - 128
      - 256
      - 512
  BACKBONE:
    FREEZE_AT: 2
    NAME: build_resnet_backbone
  CLIP_PIXEL_MEAN:
  - 122.7709383
  - 116.7460125
  - 104.09373615
  CLIP_PIXEL_STD:
  - 68.5005327
  - 66.6321579
  - 70.323163
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: ''
    OUT_CHANNELS: 256
  KEYPOINT_ON: false
  LOAD_PROPOSALS: false
  MASK_FORMER:
    SIZE_DIVISIBILITY: 32
  MASK_ON: false
  META_ARCHITECTURE: CATSeg
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: true
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN:
  - 123.675
  - 116.28
  - 103.53
  PIXEL_STD:
  - 58.395
  - 57.12
  - 57.375
  PROMPT_ENSEMBLE: false
  PROMPT_ENSEMBLE_TYPE: single
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: RPN
  RESNETS:
    DEFORM_MODULATED: false
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE:
    - false
    - false
    - false
    - false
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES:
    - res4
    RES2_OUT_CHANNELS: 256
    RES4_DILATION: 1
    RES5_DILATION: 1
    RES5_MULTI_GRID:
    - 1
    - 2
    - 4
    STEM_OUT_CHANNELS: 64
    STEM_TYPE: deeplab
    STRIDE_IN_1X1: true
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_WEIGHTS: &id002
    - 1.0
    - 1.0
    - 1.0
    - 1.0
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES:
    - p3
    - p4
    - p5
    - p6
    - p7
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.4
    - 0.5
    NMS_THRESH_TEST: 0.5
    NORM: ''
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS:
    - &id001
      - 10.0
      - 10.0
      - 5.0
      - 5.0
    - - 20.0
      - 20.0
      - 10.0
      - 10.0
    - - 30.0
      - 30.0
      - 15.0
      - 15.0
    IOUS:
    - 0.5
    - 0.6
    - 0.7
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id001
    CLS_AGNOSTIC_BBOX_REG: false
    CONV_DIM: 256
    FC_DIM: 1024
    FED_LOSS_FREQ_WEIGHT_POWER: 0.5
    FED_LOSS_NUM_CLASSES: 50
    NAME: ''
    NORM: ''
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: false
    USE_FED_LOSS: false
    USE_SIGMOID_CE: false
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 512
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - 1
    IOU_THRESHOLDS:
    - 0.5
    NAME: Res5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    POSITIVE_FRACTION: 0.25
    PROPOSAL_APPEND_GT: true
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS:
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    - 512
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: true
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: false
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: ''
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: *id002
    BOUNDARY_THRESH: -1
    CONV_DIMS:
    - -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES:
    - res4
    IOU_LABELS:
    - 0
    - -1
    - 1
    IOU_THRESHOLDS:
    - 0.3
    - 0.7
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 1000
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    APPEARANCE_GUIDANCE_DIM: 512
    APPEARANCE_GUIDANCE_PROJ_DIM: 128
    ASPP_CHANNELS: 256
    ASPP_DILATIONS:
    - 6
    - 12
    - 18
    ASPP_DROPOUT: 0.1
    ATTENTION_TYPE: linear
    CLIP_FINETUNE: attention
    CLIP_PRETRAINED: ViT-B/16
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    DECODER_DIMS:
    - 64
    - 32
    DECODER_GUIDANCE_DIMS:
    - 256
    - 128
    DECODER_GUIDANCE_PROJ_DIMS:
    - 32
    - 16
    FEATURE_RESOLUTION:
    - 24
    - 24
    HIDDEN_DIMS: 128
    IGNORE_VALUE: 255
    IN_FEATURES:
    - res2
    - res3
    - res4
    LOSS_TYPE: hard_pixel_mining
    LOSS_WEIGHT: 1.0
    NAME: CATSegHead
    NORM: GN
    NUM_CLASSES: 171
    NUM_HEADS: 4
    NUM_LAYERS: 2
    POOLING_SIZES:
    - 1
    - 1
    PROJECT_CHANNELS:
    - 48
    PROJECT_FEATURES:
    - res2
    PROMPT_DEPTH: 0
    PROMPT_LENGTH: 0
    TEST_CLASS_INDEXES: datasets/coco/coco_stuff/split/unseen_indexes.json
    TEST_CLASS_JSON: datasets/flair.json
    TEXT_GUIDANCE_DIM: 512
    TEXT_GUIDANCE_PROJ_DIM: 128
    TRAIN_CLASS_INDEXES: datasets/coco/coco_stuff/split/seen_indexes.json
    TRAIN_CLASS_JSON: datasets/coco.json
    USE_DEPTHWISE_SEPARABLE_CONV: false
    WINDOW_SIZES: 12
  SWIN:
    APE: false
    ATTN_DROP_RATE: 0.0
    DEPTHS:
    - 2
    - 2
    - 6
    - 2
    DROP_PATH_RATE: 0.3
    DROP_RATE: 0.0
    EMBED_DIM: 96
    MLP_RATIO: 4.0
    NUM_HEADS:
    - 3
    - 6
    - 12
    - 24
    OUT_FEATURES:
    - res2
    - res3
    - res4
    - res5
    PATCH_NORM: true
    PATCH_SIZE: 4
    PRETRAIN_IMG_SIZE: 224
    QKV_BIAS: true
    QK_SCALE: null
    WINDOW_SIZE: 7
  WEIGHTS: /media/zpp2/PHDD/output/new-cat-seg-results/model_base.pth
OUTPUT_DIR: ./vizDebug/
SEED: -1
SOLVER:
  AMP:
    ENABLED: false
  BACKBONE_MULTIPLIER: 0.0
  BASE_LR: 0.0002
  BASE_LR_END: 0.0
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 5000
  CLIP_GRADIENTS:
    CLIP_TYPE: full_model
    CLIP_VALUE: 0.01
    ENABLED: true
    NORM_TYPE: 2.0
  CLIP_MULTIPLIER: 0.01
  GAMMA: 0.1
  IMS_PER_BATCH: 1
  LR_SCHEDULER_NAME: WarmupCosineLR
  MAX_ITER: 80000
  MOMENTUM: 0.9
  NESTEROV: false
  NUM_DECAYS: 3
  OPTIMIZER: ADAMW
  POLY_LR_CONSTANT_ENDING: 0.0
  POLY_LR_POWER: 0.9
  REFERENCE_WORLD_SIZE: 0
  RESCALE_INTERVAL: false
  STEPS:
  - 30000
  WARMUP_FACTOR: 1.0
  WARMUP_ITERS: 0
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: null
  WEIGHT_DECAY_EMBED: 0.0
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: false
    FLIP: true
    MAX_SIZE: 4000
    MIN_SIZES:
    - 400
    - 500
    - 600
    - 700
    - 800
    - 900
    - 1000
    - 1100
    - 1200
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 5000
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: false
    NUM_ITER: 200
  SLIDING_WINDOW: true
VERSION: 2
VIS_PERIOD: 0

[06/03 22:56:36] detectron2 INFO: Full config saved to ./vizDebug/config.yaml
[06/03 22:56:36] d2.utils.env INFO: Using a generated random seed 37012722
[06/03 22:56:39] d2.engine.defaults INFO: Model:
CATSeg(
  (sem_seg_head): CATSegHead(
    (predictor): CATSegPredictor(
      (clip_model): CLIP(
        (visual): VisualTransformer(
          (conv1): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (transformer): Transformer(
            (resblocks): Sequential(
              (0): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (1): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (2): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (3): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (4): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (5): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (6): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (7): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (8): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (9): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (10): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
              (11): ResidualAttentionBlock(
                (attn): Attention(
                  (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
                )
                (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
                (mlp): Sequential(
                  (c_fc): Linear(in_features=768, out_features=3072, bias=True)
                  (gelu): QuickGELU()
                  (c_proj): Linear(in_features=3072, out_features=768, bias=True)
                )
                (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
              )
            )
          )
          (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (transformer): Transformer(
          (resblocks): Sequential(
            (0): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (1): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (2): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (3): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (4): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (5): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (6): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (7): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (8): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (9): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (10): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
            (11): ResidualAttentionBlock(
              (attn): Attention(
                (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
              )
              (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
              (mlp): Sequential(
                (c_fc): Linear(in_features=512, out_features=2048, bias=True)
                (gelu): QuickGELU()
                (c_proj): Linear(in_features=2048, out_features=512, bias=True)
              )
              (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (token_embedding): Embedding(49408, 512)
        (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
      )
      (transformer): Aggregator(
        (layers): ModuleList(
          (0-1): 2 x AggregatorLayer(
            (swin_block): SwinTransformerBlockWrapper(
              (block_1): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (block_2): SwinTransformerBlock(
                (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (attn): WindowAttention(
                  (q): Linear(in_features=256, out_features=128, bias=True)
                  (k): Linear(in_features=256, out_features=128, bias=True)
                  (v): Linear(in_features=128, out_features=128, bias=True)
                  (attn_drop): Dropout(p=0.0, inplace=False)
                  (proj): Linear(in_features=128, out_features=128, bias=True)
                  (proj_drop): Dropout(p=0.0, inplace=False)
                  (softmax): Softmax(dim=-1)
                )
                (drop_path): Identity()
                (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
                (mlp): Mlp(
                  (fc1): Linear(in_features=128, out_features=512, bias=True)
                  (act): GELU(approximate='none')
                  (drop1): Dropout(p=0.0, inplace=False)
                  (fc2): Linear(in_features=512, out_features=128, bias=True)
                  (drop2): Dropout(p=0.0, inplace=False)
                )
              )
              (guidance_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
            (attention): ClassTransformerLayer(
              (pool): AvgPool2d(kernel_size=[1, 1], stride=[1, 1], padding=0)
              (attention): AttentionLayer(
                (q): Linear(in_features=256, out_features=128, bias=True)
                (k): Linear(in_features=256, out_features=128, bias=True)
                (v): Linear(in_features=128, out_features=128, bias=True)
                (attention): LinearAttention()
              )
              (MLP): Sequential(
                (0): Linear(in_features=128, out_features=512, bias=True)
                (1): ReLU()
                (2): Linear(in_features=512, out_features=128, bias=True)
              )
              (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
              (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)
            )
          )
        )
        (conv1): Conv2d(1, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (guidance_projection): Sequential(
          (0): Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
          (1): ReLU()
        )
        (text_guidance_projection): Sequential(
          (0): Linear(in_features=512, out_features=128, bias=True)
          (1): ReLU()
        )
        (decoder_guidance_projection): ModuleList(
          (0): Sequential(
            (0): Conv2d(256, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
          (1): Sequential(
            (0): Conv2d(128, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
            (1): ReLU()
          )
        )
        (decoder1): Up(
          (up): ConvTranspose2d(128, 96, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(4, 64, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(4, 64, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (decoder2): Up(
          (up): ConvTranspose2d(64, 48, kernel_size=(2, 2), stride=(2, 2))
          (conv): DoubleConv(
            (double_conv): Sequential(
              (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (1): GroupNorm(2, 32, eps=1e-05, affine=True)
              (2): ReLU(inplace=True)
              (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
              (4): GroupNorm(2, 32, eps=1e-05, affine=True)
              (5): ReLU(inplace=True)
            )
          )
        )
        (head): Conv2d(32, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      )
    )
  )
  (upsample1): ConvTranspose2d(768, 256, kernel_size=(2, 2), stride=(2, 2))
  (upsample2): ConvTranspose2d(768, 128, kernel_size=(4, 4), stride=(4, 4))
)
[06/03 22:56:39] d2.checkpoint.detection_checkpoint INFO: [DetectionCheckpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/model_base.pth ...
[06/03 22:56:39] fvcore.common.checkpoint INFO: [Checkpointer] Loading from /media/zpp2/PHDD/output/new-cat-seg-results/model_base.pth ...
[06/03 22:56:40] d2.data.datasets.coco INFO: Loaded 15700 images with semantic segmentation from /home/zpp2/ycy/datasets/FLAIR/FLAIR_test/image
[06/03 22:56:40] d2.data.dataset_mapper INFO: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(640, 640), max_size=2560, sample_style='choice')]
[06/03 22:56:40] d2.data.common INFO: Serializing the dataset using: <class 'detectron2.data.common._TorchSerializedList'>
[06/03 22:56:40] d2.data.common INFO: Serializing 15700 elements to byte tensors and concatenating them all ...
[06/03 22:56:40] d2.data.common INFO: Serialized dataset takes 2.50 MiB
[06/03 22:56:40] d2.data.datasets.coco INFO: Loaded 15700 images with semantic segmentation from /home/zpp2/ycy/datasets/FLAIR/FLAIR_test/image
[06/03 22:56:40] d2.evaluation.evaluator INFO: Start inference on 15700 batches
